# Tai-Ahom Manuscripts Digitization & Translation

## ğŸ“‹ Overview

This project is part of our **B.Tech CSE Final Year** work.  
We aim to digitize, preserve, and translate endangered Tai-Ahom manuscripts using:

- OCR (Optical Character Recognition) â†’ Convert scanned manuscripts into digital text
- Machine Translation (MT) â†’ Translate from Ahom â†’ Assamese â†’ English
- Web Portal â†’ Make manuscripts accessible online

---

## ğŸ“ Repository Structure

```
tai-ahom/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Extracted manuscript scans (PNG)
â”‚   â”œâ”€â”€ clean/                  # Preprocessed images (denoised, binarized, deskewed)
â”‚   â””â”€â”€ gt/                     # Ground-truth transcriptions (for OCR training)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ references/             # Extracted text pages from PDFs
â”‚   â”œâ”€â”€ metadata.json           # Manuscript metadata and annotations
â”‚   â””â”€â”€ progress_reports/       # Weekly/monthly progress documentation
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ocr/                    # OCR models (Tesseract, TrOCR)
â”‚   â””â”€â”€ mt/                     # Translation models (mBART, NLLB)
â”œâ”€â”€ notebooks/                  # Jupyter/Colab notebooks for experiments
â”œâ”€â”€ portal/                     # Web application (React + Node.js)
â”œâ”€â”€ extract_pdf.py              # Script to extract text/images/metadata from PDFs
â”œâ”€â”€ preprocess_images.py        # Script to preprocess manuscript images
â””â”€â”€ prepare_tesseract_training.py # Script to prepare training data
```

---

##  Features (Planned)

- Data Collection & Cleanup â†’ Extract, preprocess, and annotate manuscripts
- OCR â†’ Fine-tune Tesseract/TrOCR for Ahom script recognition
- Machine Translation â†’ Build parallel corpus and fine-tune MT models
- Web Portal â†’ Upload manuscripts â†’ OCR â†’ Translate â†’ Save results
- Evaluation â†’ Measure OCR (CER) and MT (BLEU/chrF) scores

---

## Getting Started

### Prerequisites

- Python 3.8 or higher
- Node.js 16+ (for web portal)
- Git
- (Optional) CUDA-capable GPU for model training

### 1. Clone the Repository

```bash
git clone https://github.com/suvamneog/tai-ahom.git
cd tai-ahom
```

### 2. Install Dependencies

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt
```

### 3. Extract Data from PDF

```bash
python3 extract_pdf.py
```

### 4. Preprocess Images

```bash
python3 preprocess_images.py
```

### 5. Prepare Training Data

```bash
python3 prepare_tesseract_training.py
```

### 6. Set Up Web Portal (Optional)

```bash
cd portal
npm install
npm run dev
```

---

## ğŸ‘¥ Team Roles

| Team | Responsibilities |
|------|------------------|
|  Data Team | Collect manuscripts, clean images, annotate ground truth |
|  OCR Team | Train OCR models (Tesseract/TrOCR) |
|  MT Team | Build translation dataset and train MT models |
|  Web Team | Build portal (React + Node.js) |

---

##  Project Tracking

We maintain a Google Sheet Tracker with tasks, owners, deadlines, and evidence links.  

---

##  Current Status

###  Completed
- [x] Repository structured
- [x] Extracted text, images, and metadata from manuscripts
- [x] Preprocessed manuscript scans
- [x] OCR training pipeline ready (awaiting ground truth transcription)

### ğŸ”„ In Progress
- [ ] Manual transcription for ground truth (`data/gt/`)
- [ ] Fine-tune Tesseract OCR on Ahom script
- [ ] Build translation corpus (Ahom â†’ Assamese â†’ English)
- [ ] Setup web portal for user interaction
- [ ] Weekly progress documentation

---

##  Next Steps

1. Manual transcription for ground truth (`data/gt/`)
2. Fine-tune Tesseract OCR on Ahom script
3. Build translation corpus (Ahom â†’ Assamese â†’ English)
4. Setup web portal for user interaction
5. Weekly progress documentation

---

## Model Evaluation

### OCR Metrics
- CER (Character Error Rate) â†’ Primary metric for OCR accuracy
- WER (Word Error Rate) â†’ Secondary metric for word-level accuracy

### Translation Metrics
- BLEU Score â†’ Primary metric for translation quality
- chrF Score â†’ Character-level F-score for translation evaluation

---

##  Technology Stack

- OCR: Tesseract, TrOCR (Transformer-based OCR)
- Machine Translation: mBART, NLLB (No Language Left Behind)
- Web Portal: React.js + Node.js + Express
- Image Processing: OpenCV, PIL
- Machine Learning: PyTorch, Transformers

---

##  License

This project is for **academic research & preservation purposes only**.

### Usage Rights
-  Academic research and educational purposes
-  Non-commercial cultural preservation efforts
-  Citation in academic publications (with proper attribution)
-  Commercial use without explicit permission
-  Redistribution without source attribution

---

##  Acknowledgments

- Cultural Consultants â†’ Tai-Ahom community elders and scholars
- Technical Mentors â†’ Faculty advisors and industry experts
- Data Contributors â†’ Museums, libraries, and private collectors
- Open Source Community â†’ Tesseract, Hugging Face, and related projects

---

Preserving the past, building the future.
